{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df = pd.read_csv('../data/processed/processed_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>style</th>\n",
       "      <th>living_area</th>\n",
       "      <th>lot_dimensions</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>levels</th>\n",
       "      <th>location</th>\n",
       "      <th>listing_date</th>\n",
       "      <th>year_of_construction</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 storey</td>\n",
       "      <td>1191</td>\n",
       "      <td>4076</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beauport</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2004</td>\n",
       "      <td>332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Open area</td>\n",
       "      <td>1261</td>\n",
       "      <td>9500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Deschambault</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>1957</td>\n",
       "      <td>265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1645</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mercier</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Link</td>\n",
       "      <td>2024</td>\n",
       "      <td>17000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Stoneham</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 storey</td>\n",
       "      <td>2400</td>\n",
       "      <td>4471</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Gatineau</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>1989</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       style  living_area  lot_dimensions  bedrooms  bathrooms  levels  \\\n",
       "0   2 storey         1191            4076         3          1       2   \n",
       "1  Open area         1261            9500         2          1       1   \n",
       "2    Unknown         1645            1360         3          1       3   \n",
       "3       Link         2024           17000         4          3       1   \n",
       "4   2 storey         2400            4471         4          2       2   \n",
       "\n",
       "       location listing_date  year_of_construction   price  \n",
       "0      Beauport   2020-12-01                  2004  332500  \n",
       "1  Deschambault   2021-12-01                  1957  265000  \n",
       "2       Mercier   2021-11-01                  2006  612000  \n",
       "3      Stoneham   2021-12-01                  2019  526500  \n",
       "4      Gatineau   2021-12-01                  1989  360000  "
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df.insert(7, 'year', '')\n",
    "listings_df['year'] = pd.DatetimeIndex(listings_df['listing_date']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "def plot_corr_map(df):\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_corr_map(listings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols = ['location', 'year']\n",
    "one_hot_cols = ['bedrooms', 'bathrooms']\n",
    "numerical_cols = ['living_area']\n",
    "target_col = ['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df = listings_df[ordinal_cols + one_hot_cols + numerical_cols + target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_encode(df_line, col, new_col, val):\n",
    "    if df_line[col] == val:\n",
    "        return df_line[new_col] + 1\n",
    "    else:\n",
    "        return df_line[new_col]\n",
    "\n",
    "for col in one_hot_cols:\n",
    "    for val in listings_df[col].unique():   \n",
    "        new_col = str(val) + '_' + col\n",
    "        listings_df[new_col] = 0\n",
    "        listings_df[new_col] = listings_df.apply(oh_encode, args=(col, new_col, val), axis=1)\n",
    "\n",
    "    listings_df = listings_df.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>living_area</th>\n",
       "      <th>price</th>\n",
       "      <th>3_bedrooms</th>\n",
       "      <th>2_bedrooms</th>\n",
       "      <th>4_bedrooms</th>\n",
       "      <th>5_bedrooms</th>\n",
       "      <th>6_bedrooms</th>\n",
       "      <th>1_bedrooms</th>\n",
       "      <th>1_bathrooms</th>\n",
       "      <th>3_bathrooms</th>\n",
       "      <th>2_bathrooms</th>\n",
       "      <th>4_bathrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauport</td>\n",
       "      <td>2020</td>\n",
       "      <td>1191</td>\n",
       "      <td>332500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deschambault</td>\n",
       "      <td>2021</td>\n",
       "      <td>1261</td>\n",
       "      <td>265000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercier</td>\n",
       "      <td>2021</td>\n",
       "      <td>1645</td>\n",
       "      <td>612000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stoneham</td>\n",
       "      <td>2021</td>\n",
       "      <td>2024</td>\n",
       "      <td>526500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gatineau</td>\n",
       "      <td>2021</td>\n",
       "      <td>2400</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  year  living_area   price  3_bedrooms  2_bedrooms  \\\n",
       "0      Beauport  2020         1191  332500           1           0   \n",
       "1  Deschambault  2021         1261  265000           0           1   \n",
       "2       Mercier  2021         1645  612000           1           0   \n",
       "3      Stoneham  2021         2024  526500           0           0   \n",
       "4      Gatineau  2021         2400  360000           0           0   \n",
       "\n",
       "   4_bedrooms  5_bedrooms  6_bedrooms  1_bedrooms  1_bathrooms  3_bathrooms  \\\n",
       "0           0           0           0           0            1            0   \n",
       "1           0           0           0           0            1            0   \n",
       "2           0           0           0           0            1            0   \n",
       "3           1           0           0           0            0            1   \n",
       "4           1           0           0           0            0            0   \n",
       "\n",
       "   2_bathrooms  4_bathrooms  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            1            0  "
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = listings_df[target_col]\n",
    "X = listings_df.drop(columns=target_col)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoders = {}\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    ordinal_encoders[col] = OrdinalEncoder()\n",
    "    X_train[col] = ordinal_encoders[col].fit_transform(X_train[[col]])\n",
    "    X_test[col] = ordinal_encoders[col].transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "\n",
    "for col in numerical_cols:\n",
    "    scalers[col] = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X_train[col] = scalers[col].fit_transform(X_train[[col]])\n",
    "    X_test[col] = scalers[col].transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_target = True\n",
    "\n",
    "if scale_target:\n",
    "    target_scaler = MinMaxScaler((-1, 1))\n",
    "\n",
    "    y_train = target_scaler.fit_transform(y_train)\n",
    "    y_test = target_scaler.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>living_area</th>\n",
       "      <th>3_bedrooms</th>\n",
       "      <th>2_bedrooms</th>\n",
       "      <th>4_bedrooms</th>\n",
       "      <th>5_bedrooms</th>\n",
       "      <th>6_bedrooms</th>\n",
       "      <th>1_bedrooms</th>\n",
       "      <th>1_bathrooms</th>\n",
       "      <th>3_bathrooms</th>\n",
       "      <th>2_bathrooms</th>\n",
       "      <th>4_bathrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.718497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58829</th>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.734682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29760</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.475723</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41040</th>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.387861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27406</th>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.778613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  year  living_area  3_bedrooms  2_bedrooms  4_bedrooms  \\\n",
       "17498       3.0  14.0    -0.718497           0           0           1   \n",
       "58829      11.0  18.0    -0.734682           1           0           0   \n",
       "29760       4.0   9.0    -0.475723           1           0           0   \n",
       "41040      31.0  18.0    -0.387861           0           0           0   \n",
       "27406      27.0  11.0    -0.778613           0           0           1   \n",
       "\n",
       "       5_bedrooms  6_bedrooms  1_bedrooms  1_bathrooms  3_bathrooms  \\\n",
       "17498           0           0           0            0            0   \n",
       "58829           0           0           0            0            0   \n",
       "29760           0           0           0            0            0   \n",
       "41040           1           0           0            0            0   \n",
       "27406           0           0           0            1            0   \n",
       "\n",
       "       2_bathrooms  4_bathrooms  \n",
       "17498            1            0  \n",
       "58829            1            0  \n",
       "29760            1            0  \n",
       "41040            1            0  \n",
       "27406            0            0  "
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53674607],\n",
       "       [-0.21236695],\n",
       "       [-0.38063862],\n",
       "       ...,\n",
       "       [-0.49619868],\n",
       "       [-0.57729346],\n",
       "       [-0.34921439]])"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36109485683429143"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_127 (Dense)           (None, 13)                182       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 10)                140       \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 4)                 44        \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\Documents\\GitHub\\quebec-real-estate\\venv\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.4402 - val_loss: 0.1089\n",
      "Epoch 2/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0733\n",
      "Epoch 3/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0632\n",
      "Epoch 4/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0515 - val_loss: 0.0543\n",
      "Epoch 5/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0480\n",
      "Epoch 6/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0385 - val_loss: 0.0424\n",
      "Epoch 7/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0347 - val_loss: 0.0391\n",
      "Epoch 8/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.0372\n",
      "Epoch 9/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.0361\n",
      "Epoch 10/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.0346\n",
      "Epoch 11/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0285 - val_loss: 0.0338\n",
      "Epoch 12/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0278 - val_loss: 0.0330\n",
      "Epoch 13/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0272 - val_loss: 0.0335\n",
      "Epoch 14/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0318\n",
      "Epoch 15/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0313\n",
      "Epoch 16/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.0311\n",
      "Epoch 17/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0308\n",
      "Epoch 18/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0311\n",
      "Epoch 19/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0307\n",
      "Epoch 20/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0298\n",
      "Epoch 21/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0308\n",
      "Epoch 22/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0292\n",
      "Epoch 23/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.0296\n",
      "Epoch 24/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.0296\n",
      "Epoch 25/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.0291\n",
      "Epoch 26/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0282\n",
      "Epoch 27/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0302\n",
      "Epoch 28/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0295\n",
      "Epoch 29/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.0293\n",
      "Epoch 30/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0282\n",
      "Epoch 31/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0283\n",
      "Epoch 32/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0278\n",
      "Epoch 33/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0277\n",
      "Epoch 34/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.0283\n",
      "Epoch 35/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0285\n",
      "Epoch 36/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0281\n",
      "Epoch 37/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0282\n",
      "Epoch 38/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0273\n",
      "Epoch 39/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0222 - val_loss: 0.0283\n",
      "Epoch 40/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0272\n",
      "Epoch 41/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.0266\n",
      "Epoch 42/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0275\n",
      "Epoch 43/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0274\n",
      "Epoch 44/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0270\n",
      "Epoch 45/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0257\n",
      "Epoch 46/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.0263\n",
      "Epoch 47/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0263\n",
      "Epoch 48/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0261\n",
      "Epoch 49/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0263\n",
      "Epoch 50/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0261\n",
      "Epoch 51/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0260\n",
      "Epoch 52/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0268\n",
      "Epoch 53/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0264\n",
      "Epoch 54/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0255\n",
      "Epoch 55/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0257\n",
      "Epoch 56/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 57/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0252\n",
      "Epoch 58/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0250\n",
      "Epoch 59/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0241\n",
      "Epoch 60/700\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.018 - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0251\n",
      "Epoch 61/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0250\n",
      "Epoch 62/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0248\n",
      "Epoch 63/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0244\n",
      "Epoch 64/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0243\n",
      "Epoch 65/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0244\n",
      "Epoch 66/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0246\n",
      "Epoch 67/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0246\n",
      "Epoch 68/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0239\n",
      "Epoch 69/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0228\n",
      "Epoch 70/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0234\n",
      "Epoch 71/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0261\n",
      "Epoch 72/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0249\n",
      "Epoch 73/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0240\n",
      "Epoch 74/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0252\n",
      "Epoch 75/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0251\n",
      "Epoch 76/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0239\n",
      "Epoch 77/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0243\n",
      "Epoch 78/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0227\n",
      "Epoch 79/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0257\n",
      "Epoch 80/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0238\n",
      "Epoch 81/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0236\n",
      "Epoch 82/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0246\n",
      "Epoch 83/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0238\n",
      "Epoch 84/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0245\n",
      "Epoch 85/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 86/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 87/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0234\n",
      "Epoch 88/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 89/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0245\n",
      "Epoch 90/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0237\n",
      "Epoch 91/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0239\n",
      "Epoch 92/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0236\n",
      "Epoch 93/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0242\n",
      "Epoch 94/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0232\n",
      "Epoch 95/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0238\n",
      "Epoch 96/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0241\n",
      "Epoch 97/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0232\n",
      "Epoch 98/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0226\n",
      "Epoch 99/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0227\n",
      "Epoch 100/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0240\n",
      "Epoch 101/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0234\n",
      "Epoch 102/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0226\n",
      "Epoch 103/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0234\n",
      "Epoch 104/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0243\n",
      "Epoch 105/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0234\n",
      "Epoch 106/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0226\n",
      "Epoch 107/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0221\n",
      "Epoch 108/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0223\n",
      "Epoch 109/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0237\n",
      "Epoch 110/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0223\n",
      "Epoch 111/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0233\n",
      "Epoch 112/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0233\n",
      "Epoch 113/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0231\n",
      "Epoch 114/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0228\n",
      "Epoch 115/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0237\n",
      "Epoch 116/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0223\n",
      "Epoch 117/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0221\n",
      "Epoch 118/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0235\n",
      "Epoch 119/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0221\n",
      "Epoch 120/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0228\n",
      "Epoch 121/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0234\n",
      "Epoch 122/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 123/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0233\n",
      "Epoch 124/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0226\n",
      "Epoch 125/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0227\n",
      "Epoch 126/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0226\n",
      "Epoch 127/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0222\n",
      "Epoch 128/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0233\n",
      "Epoch 129/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0223\n",
      "Epoch 130/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0230\n",
      "Epoch 131/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0223\n",
      "Epoch 132/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0226\n",
      "Epoch 133/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0228\n",
      "Epoch 134/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0224\n",
      "Epoch 135/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0212\n",
      "Epoch 136/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0223\n",
      "Epoch 137/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0233\n",
      "Epoch 138/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0220\n",
      "Epoch 139/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0224\n",
      "Epoch 140/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0214\n",
      "Epoch 141/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 142/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0216\n",
      "Epoch 143/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0224\n",
      "Epoch 144/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0208\n",
      "Epoch 145/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0212\n",
      "Epoch 146/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 147/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0224\n",
      "Epoch 148/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0221\n",
      "Epoch 149/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0217\n",
      "Epoch 150/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0211\n",
      "Epoch 151/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0220\n",
      "Epoch 152/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0230\n",
      "Epoch 153/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0224\n",
      "Epoch 154/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0229\n",
      "Epoch 155/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0226\n",
      "Epoch 156/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0218\n",
      "Epoch 157/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0222\n",
      "Epoch 158/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0214\n",
      "Epoch 159/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0222\n",
      "Epoch 160/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0215\n",
      "Epoch 161/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0211\n",
      "Epoch 162/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0219\n",
      "Epoch 163/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0212\n",
      "Epoch 164/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0209\n",
      "Epoch 165/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0206\n",
      "Epoch 166/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0223\n",
      "Epoch 167/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0212\n",
      "Epoch 168/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0218\n",
      "Epoch 169/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0217\n",
      "Epoch 170/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0210\n",
      "Epoch 171/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0218\n",
      "Epoch 172/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0211\n",
      "Epoch 173/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0216\n",
      "Epoch 174/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0214\n",
      "Epoch 175/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0204\n",
      "Epoch 176/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0206\n",
      "Epoch 177/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 178/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0215\n",
      "Epoch 179/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0205\n",
      "Epoch 180/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0225\n",
      "Epoch 181/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0223\n",
      "Epoch 182/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0218\n",
      "Epoch 183/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0216\n",
      "Epoch 184/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 185/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0216\n",
      "Epoch 186/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0217\n",
      "Epoch 187/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0207\n",
      "Epoch 188/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0220\n",
      "Epoch 189/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0213\n",
      "Epoch 190/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0206\n",
      "Epoch 191/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0221\n",
      "Epoch 192/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0227\n",
      "Epoch 193/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0227\n",
      "Epoch 194/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0210\n",
      "Epoch 195/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0208\n",
      "Epoch 196/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0210\n",
      "Epoch 197/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0198\n",
      "Epoch 198/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0206\n",
      "Epoch 199/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0214\n",
      "Epoch 200/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0205\n",
      "Epoch 201/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0209\n",
      "Epoch 202/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0224\n",
      "Epoch 203/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0213\n",
      "Epoch 204/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0207\n",
      "Epoch 205/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0200\n",
      "Epoch 206/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0208\n",
      "Epoch 207/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0208\n",
      "Epoch 208/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0213\n",
      "Epoch 209/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0201\n",
      "Epoch 210/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0215\n",
      "Epoch 211/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0208\n",
      "Epoch 212/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0200\n",
      "Epoch 213/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0203\n",
      "Epoch 214/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0202\n",
      "Epoch 215/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0210\n",
      "Epoch 216/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0218\n",
      "Epoch 217/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0206\n",
      "Epoch 218/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0202\n",
      "Epoch 219/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0222\n",
      "Epoch 220/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0224\n",
      "Epoch 221/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0223\n",
      "Epoch 222/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0206\n",
      "Epoch 223/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0206\n",
      "Epoch 224/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0209\n",
      "Epoch 225/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0212\n",
      "Epoch 226/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 227/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0214\n",
      "Epoch 228/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0201\n",
      "Epoch 229/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 230/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0198\n",
      "Epoch 231/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 232/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0208\n",
      "Epoch 233/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0201\n",
      "Epoch 234/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0202\n",
      "Epoch 235/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0204\n",
      "Epoch 236/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0198\n",
      "Epoch 237/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0209\n",
      "Epoch 238/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0206\n",
      "Epoch 239/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0210\n",
      "Epoch 240/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0213\n",
      "Epoch 241/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0206\n",
      "Epoch 242/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0200\n",
      "Epoch 243/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0213\n",
      "Epoch 244/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0209\n",
      "Epoch 245/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0214\n",
      "Epoch 246/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0216\n",
      "Epoch 247/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0214\n",
      "Epoch 248/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0209\n",
      "Epoch 249/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0212\n",
      "Epoch 250/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0206\n",
      "Epoch 251/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0193\n",
      "Epoch 252/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0202\n",
      "Epoch 253/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0204\n",
      "Epoch 254/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0205\n",
      "Epoch 255/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0205\n",
      "Epoch 256/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0210\n",
      "Epoch 257/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0206\n",
      "Epoch 258/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0204\n",
      "Epoch 259/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0211\n",
      "Epoch 260/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0205\n",
      "Epoch 261/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0199\n",
      "Epoch 262/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0201\n",
      "Epoch 263/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0210\n",
      "Epoch 264/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0200\n",
      "Epoch 265/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0193\n",
      "Epoch 266/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0195\n",
      "Epoch 267/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0205\n",
      "Epoch 268/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0199\n",
      "Epoch 269/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0202\n",
      "Epoch 270/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0203\n",
      "Epoch 271/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0220\n",
      "Epoch 272/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0205\n",
      "Epoch 273/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0201\n",
      "Epoch 274/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0203\n",
      "Epoch 275/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0207\n",
      "Epoch 276/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0206\n",
      "Epoch 277/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0206\n",
      "Epoch 278/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0211\n",
      "Epoch 279/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0188\n",
      "Epoch 280/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0209\n",
      "Epoch 281/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0196\n",
      "Epoch 282/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0200\n",
      "Epoch 283/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0205\n",
      "Epoch 284/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0209\n",
      "Epoch 285/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 286/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0213\n",
      "Epoch 287/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0199\n",
      "Epoch 288/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0196\n",
      "Epoch 289/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0211\n",
      "Epoch 290/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0204\n",
      "Epoch 291/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0205\n",
      "Epoch 292/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0206\n",
      "Epoch 293/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0211\n",
      "Epoch 294/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0211\n",
      "Epoch 295/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0214\n",
      "Epoch 296/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0195\n",
      "Epoch 297/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0203\n",
      "Epoch 298/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 299/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0202\n",
      "Epoch 300/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 301/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0195\n",
      "Epoch 302/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0204\n",
      "Epoch 303/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 304/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0204\n",
      "Epoch 305/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0207\n",
      "Epoch 306/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 307/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0195\n",
      "Epoch 308/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0196\n",
      "Epoch 309/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0207\n",
      "Epoch 310/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0195\n",
      "Epoch 311/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 312/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 313/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0211\n",
      "Epoch 314/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0202\n",
      "Epoch 315/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0204\n",
      "Epoch 316/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0196\n",
      "Epoch 317/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0216\n",
      "Epoch 318/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0208\n",
      "Epoch 319/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0195\n",
      "Epoch 320/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0198\n",
      "Epoch 321/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0206\n",
      "Epoch 322/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0206\n",
      "Epoch 323/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0221\n",
      "Epoch 324/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0198\n",
      "Epoch 325/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0192\n",
      "Epoch 326/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 327/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 328/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0205\n",
      "Epoch 329/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0206\n",
      "Epoch 330/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0209\n",
      "Epoch 331/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0211\n",
      "Epoch 332/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 333/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0195\n",
      "Epoch 334/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0210\n",
      "Epoch 335/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0211\n",
      "Epoch 336/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0201\n",
      "Epoch 337/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0218\n",
      "Epoch 338/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 339/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0199\n",
      "Epoch 340/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 341/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 342/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0216\n",
      "Epoch 343/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0199\n",
      "Epoch 344/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 345/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 346/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0219\n",
      "Epoch 347/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0213\n",
      "Epoch 348/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 349/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 350/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 351/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 352/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 353/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0206\n",
      "Epoch 354/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0206\n",
      "Epoch 355/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0203\n",
      "Epoch 356/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 357/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 358/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 359/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 360/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 361/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0203\n",
      "Epoch 362/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0208\n",
      "Epoch 363/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 364/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 365/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0192\n",
      "Epoch 366/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0211\n",
      "Epoch 367/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0204\n",
      "Epoch 368/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0207\n",
      "Epoch 369/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0204\n",
      "Epoch 370/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0203\n",
      "Epoch 371/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 372/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0207\n",
      "Epoch 373/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0211\n",
      "Epoch 374/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 375/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0216\n",
      "Epoch 376/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0195\n",
      "Epoch 377/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 378/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 379/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0196\n",
      "Epoch 380/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 381/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0205\n",
      "Epoch 382/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 383/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0190\n",
      "Epoch 384/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 385/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 386/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0204\n",
      "Epoch 387/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 388/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 389/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0193\n",
      "Epoch 390/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 391/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 392/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0198\n",
      "Epoch 393/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0193\n",
      "Epoch 394/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 395/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0214\n",
      "Epoch 396/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0203\n",
      "Epoch 397/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 398/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0198\n",
      "Epoch 399/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 400/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0202\n",
      "Epoch 401/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 402/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0212\n",
      "Epoch 403/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 404/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 405/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 406/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0207\n",
      "Epoch 407/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0208\n",
      "Epoch 408/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0205\n",
      "Epoch 409/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0203\n",
      "Epoch 410/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0217\n",
      "Epoch 411/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0193\n",
      "Epoch 412/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0199\n",
      "Epoch 413/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 414/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0202\n",
      "Epoch 415/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0203\n",
      "Epoch 416/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0210\n",
      "Epoch 417/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0203\n",
      "Epoch 418/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 419/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0213\n",
      "Epoch 420/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 421/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0203\n",
      "Epoch 422/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 423/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0196\n",
      "Epoch 424/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0202\n",
      "Epoch 425/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0199\n",
      "Epoch 426/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 427/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 428/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 429/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0207\n",
      "Epoch 430/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0205\n",
      "Epoch 431/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0204\n",
      "Epoch 432/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0204\n",
      "Epoch 433/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0195\n",
      "Epoch 434/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0198\n",
      "Epoch 435/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0198\n",
      "Epoch 436/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0196\n",
      "Epoch 437/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0202\n",
      "Epoch 438/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 439/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0205\n",
      "Epoch 440/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 441/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 442/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0215\n",
      "Epoch 443/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0211\n",
      "Epoch 444/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0195\n",
      "Epoch 445/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0198\n",
      "Epoch 446/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 447/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0197\n",
      "Epoch 448/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 449/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 450/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 451/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0207\n",
      "Epoch 452/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 453/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0195\n",
      "Epoch 454/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 455/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0209\n",
      "Epoch 456/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0203\n",
      "Epoch 457/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0192\n",
      "Epoch 458/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0208\n",
      "Epoch 459/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0195\n",
      "Epoch 460/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0206\n",
      "Epoch 461/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0201\n",
      "Epoch 462/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0214\n",
      "Epoch 463/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0192\n",
      "Epoch 464/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 465/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 466/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0205\n",
      "Epoch 467/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 468/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0211\n",
      "Epoch 469/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0208\n",
      "Epoch 470/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0202\n",
      "Epoch 471/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0203\n",
      "Epoch 472/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0209\n",
      "Epoch 473/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 474/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 475/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0197\n",
      "Epoch 476/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0203\n",
      "Epoch 477/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0211\n",
      "Epoch 478/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0203\n",
      "Epoch 479/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0195\n",
      "Epoch 480/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 481/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0201\n",
      "Epoch 482/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0202\n",
      "Epoch 483/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0196\n",
      "Epoch 484/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0195\n",
      "Epoch 485/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0206\n",
      "Epoch 486/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0187\n",
      "Epoch 487/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 488/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0201\n",
      "Epoch 489/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0214\n",
      "Epoch 490/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 491/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 492/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0188\n",
      "Epoch 493/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 494/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0209\n",
      "Epoch 495/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0196\n",
      "Epoch 496/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0209\n",
      "Epoch 497/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0201\n",
      "Epoch 498/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0201\n",
      "Epoch 499/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0210\n",
      "Epoch 500/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0191\n",
      "Epoch 501/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0203\n",
      "Epoch 502/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 503/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0185\n",
      "Epoch 504/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 505/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0198\n",
      "Epoch 506/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 507/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0209\n",
      "Epoch 508/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 509/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 510/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0210\n",
      "Epoch 511/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 512/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 513/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0213\n",
      "Epoch 514/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0196\n",
      "Epoch 515/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 516/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 517/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0203\n",
      "Epoch 518/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0207\n",
      "Epoch 519/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0210\n",
      "Epoch 520/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 521/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0193\n",
      "Epoch 522/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0197\n",
      "Epoch 523/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0193\n",
      "Epoch 524/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 525/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 526/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0189\n",
      "Epoch 527/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0195\n",
      "Epoch 528/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0204\n",
      "Epoch 529/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 530/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0201\n",
      "Epoch 531/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0196\n",
      "Epoch 532/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0196\n",
      "Epoch 533/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0208\n",
      "Epoch 534/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0200\n",
      "Epoch 535/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0202\n",
      "Epoch 536/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0205\n",
      "Epoch 537/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 538/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0195\n",
      "Epoch 539/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 540/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 541/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0203\n",
      "Epoch 542/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0203\n",
      "Epoch 543/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0207\n",
      "Epoch 544/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 545/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0206\n",
      "Epoch 546/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 547/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0197\n",
      "Epoch 548/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 549/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0201\n",
      "Epoch 550/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0206\n",
      "Epoch 551/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0196\n",
      "Epoch 552/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 553/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0201\n",
      "Epoch 554/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0205\n",
      "Epoch 555/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0197\n",
      "Epoch 556/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 557/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0196\n",
      "Epoch 558/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 559/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0204\n",
      "Epoch 560/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 561/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0197\n",
      "Epoch 562/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 563/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 564/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0213\n",
      "Epoch 565/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 566/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0203\n",
      "Epoch 567/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0209\n",
      "Epoch 568/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0207\n",
      "Epoch 569/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0205\n",
      "Epoch 570/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0193\n",
      "Epoch 571/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0208\n",
      "Epoch 572/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0205\n",
      "Epoch 573/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0197\n",
      "Epoch 574/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0204\n",
      "Epoch 575/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 576/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0186\n",
      "Epoch 577/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 578/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 579/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 580/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0206\n",
      "Epoch 581/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 582/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 583/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0198\n",
      "Epoch 584/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0215\n",
      "Epoch 585/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0195\n",
      "Epoch 586/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0200\n",
      "Epoch 587/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 588/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 589/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 590/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 591/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 592/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0193\n",
      "Epoch 593/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 594/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 595/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0187\n",
      "Epoch 596/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 597/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 598/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0203\n",
      "Epoch 599/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0207\n",
      "Epoch 600/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 601/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 602/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0188\n",
      "Epoch 603/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 604/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0206\n",
      "Epoch 605/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 606/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 607/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0193\n",
      "Epoch 608/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0208\n",
      "Epoch 609/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0207\n",
      "Epoch 610/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0204\n",
      "Epoch 611/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0197\n",
      "Epoch 612/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 613/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 614/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 615/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0197\n",
      "Epoch 616/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0203\n",
      "Epoch 617/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 618/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0194\n",
      "Epoch 619/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 620/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0196\n",
      "Epoch 621/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 622/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 623/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 624/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0204\n",
      "Epoch 625/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 626/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0207\n",
      "Epoch 627/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0206\n",
      "Epoch 628/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 629/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0188\n",
      "Epoch 630/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0202\n",
      "Epoch 631/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0197\n",
      "Epoch 632/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 633/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0202\n",
      "Epoch 634/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0192\n",
      "Epoch 635/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 636/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0189\n",
      "Epoch 637/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 638/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 639/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0202\n",
      "Epoch 640/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0207\n",
      "Epoch 641/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0213\n",
      "Epoch 642/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0201\n",
      "Epoch 643/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0206\n",
      "Epoch 644/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0203\n",
      "Epoch 645/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0199\n",
      "Epoch 646/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0197\n",
      "Epoch 647/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0197\n",
      "Epoch 648/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 649/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0200\n",
      "Epoch 650/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0197\n",
      "Epoch 651/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 652/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0196\n",
      "Epoch 653/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0203\n",
      "Epoch 654/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 655/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0195\n",
      "Epoch 656/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0200\n",
      "Epoch 657/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 658/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 659/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0204\n",
      "Epoch 660/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 661/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0198\n",
      "Epoch 662/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0208\n",
      "Epoch 663/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0203\n",
      "Epoch 664/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0206\n",
      "Epoch 665/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 666/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 667/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0205\n",
      "Epoch 668/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 669/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0203\n",
      "Epoch 670/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 671/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 672/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 673/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 674/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0202\n",
      "Epoch 675/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 676/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 677/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 678/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 679/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0206\n",
      "Epoch 680/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 681/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0200\n",
      "Epoch 682/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 683/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0197\n",
      "Epoch 684/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0200\n",
      "Epoch 685/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0208\n",
      "Epoch 686/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0206\n",
      "Epoch 687/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0201\n",
      "Epoch 688/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0205\n",
      "Epoch 689/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0203\n",
      "Epoch 690/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0199\n",
      "Epoch 691/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 692/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0195\n",
      "Epoch 693/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0201\n",
      "Epoch 694/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0196\n",
      "Epoch 695/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0211\n",
      "Epoch 696/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0199\n",
      "Epoch 697/700\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 698/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 699/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0203\n",
      "Epoch 700/700\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0194\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=13, activation='tanh', input_shape=(X_train.shape[-1],)))\n",
    "model.add(Dense(units=10, activation='tanh'))\n",
    "model.add(Dense(units=4, activation='tanh'))\n",
    "model.add(Dense(units=1, activation='tanh'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mse')\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=1000, epochs=700, shuffle=True, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predicted_prices = target_scaler.inverse_transform(reg.predict(X_test))\n",
    "tf_predicted_prices = target_scaler.inverse_transform(model.predict(X_test))\n",
    "real_prices = target_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ordinal_cols:\n",
    "    test_df[col] = ordinal_encoders[col].inverse_transform(test_df[[col]])\n",
    "\n",
    "for col in numerical_cols:\n",
    "    test_df[col] = scalers[col].inverse_transform(test_df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['real price'] = list(real_prices)\n",
    "d['sk predicted price'] = list(sk_predicted_prices)\n",
    "d['tf predicted price'] = list(tf_predicted_prices)\n",
    "\n",
    "test_df['real price'] = d['real price']\n",
    "test_df['sk predicted price'] = d['sk predicted price']\n",
    "test_df['tf predicted price'] = d['tf predicted price']\n",
    "\n",
    "test_df['real price'] = test_df['real price'].astype(int)\n",
    "test_df['sk predicted price'] = test_df['sk predicted price'].astype(int)\n",
    "test_df['tf predicted price'] = test_df['tf predicted price'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>living_area</th>\n",
       "      <th>3_bedrooms</th>\n",
       "      <th>2_bedrooms</th>\n",
       "      <th>4_bedrooms</th>\n",
       "      <th>5_bedrooms</th>\n",
       "      <th>6_bedrooms</th>\n",
       "      <th>1_bedrooms</th>\n",
       "      <th>1_bathrooms</th>\n",
       "      <th>3_bathrooms</th>\n",
       "      <th>2_bathrooms</th>\n",
       "      <th>4_bathrooms</th>\n",
       "      <th>real price</th>\n",
       "      <th>sk predicted price</th>\n",
       "      <th>tf predicted price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47648</th>\n",
       "      <td>Alma</td>\n",
       "      <td>2021</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>284000</td>\n",
       "      <td>437759</td>\n",
       "      <td>306945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28551</th>\n",
       "      <td>Boucherville</td>\n",
       "      <td>2013</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>295000</td>\n",
       "      <td>301592</td>\n",
       "      <td>331303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39252</th>\n",
       "      <td>Lvis</td>\n",
       "      <td>2005</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155000</td>\n",
       "      <td>189011</td>\n",
       "      <td>190407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34697</th>\n",
       "      <td>Gatineau</td>\n",
       "      <td>2010</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>266000</td>\n",
       "      <td>280009</td>\n",
       "      <td>276676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32964</th>\n",
       "      <td>Neufchatel</td>\n",
       "      <td>2011</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265000</td>\n",
       "      <td>242681</td>\n",
       "      <td>235525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23878</th>\n",
       "      <td>Boucherville</td>\n",
       "      <td>2013</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695000</td>\n",
       "      <td>475647</td>\n",
       "      <td>621489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37645</th>\n",
       "      <td>St-Augustin-De-Desmaures</td>\n",
       "      <td>2008</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265000</td>\n",
       "      <td>231030</td>\n",
       "      <td>274712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34727</th>\n",
       "      <td>La Prairie</td>\n",
       "      <td>2010</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>330500</td>\n",
       "      <td>308621</td>\n",
       "      <td>371913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46894</th>\n",
       "      <td>Deschambault</td>\n",
       "      <td>2021</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265000</td>\n",
       "      <td>309425</td>\n",
       "      <td>290848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36602</th>\n",
       "      <td>Chambly</td>\n",
       "      <td>2009</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312000</td>\n",
       "      <td>222140</td>\n",
       "      <td>297002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48255</th>\n",
       "      <td>Mercier</td>\n",
       "      <td>2021</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>612000</td>\n",
       "      <td>410806</td>\n",
       "      <td>623542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>Gatineau</td>\n",
       "      <td>2016</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>380000</td>\n",
       "      <td>449032</td>\n",
       "      <td>424414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27711</th>\n",
       "      <td>Longueuil</td>\n",
       "      <td>2013</td>\n",
       "      <td>988.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232999</td>\n",
       "      <td>244119</td>\n",
       "      <td>279035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24961</th>\n",
       "      <td>Sherbrooke</td>\n",
       "      <td>2015</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197000</td>\n",
       "      <td>247299</td>\n",
       "      <td>221265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18442</th>\n",
       "      <td>Chambly</td>\n",
       "      <td>2016</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>244999</td>\n",
       "      <td>290467</td>\n",
       "      <td>300676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>Ste-Marthe-Sur-Le-Lac</td>\n",
       "      <td>2020</td>\n",
       "      <td>920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>335000</td>\n",
       "      <td>394140</td>\n",
       "      <td>293957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43345</th>\n",
       "      <td>Mercier</td>\n",
       "      <td>2021</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>612000</td>\n",
       "      <td>410806</td>\n",
       "      <td>623542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45749</th>\n",
       "      <td>Fabreville</td>\n",
       "      <td>2021</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>400000</td>\n",
       "      <td>377655</td>\n",
       "      <td>405629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44162</th>\n",
       "      <td>Beauport</td>\n",
       "      <td>2020</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>332500</td>\n",
       "      <td>348178</td>\n",
       "      <td>350134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>Blainville</td>\n",
       "      <td>2017</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251000</td>\n",
       "      <td>284461</td>\n",
       "      <td>318907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13946</th>\n",
       "      <td>Gatineau</td>\n",
       "      <td>2018</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>319000</td>\n",
       "      <td>338971</td>\n",
       "      <td>278257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50850</th>\n",
       "      <td>St-Ferrol-les-Neiges</td>\n",
       "      <td>2021</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>610000</td>\n",
       "      <td>453588</td>\n",
       "      <td>617469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>Mercier</td>\n",
       "      <td>2020</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>455000</td>\n",
       "      <td>361267</td>\n",
       "      <td>354415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57354</th>\n",
       "      <td>Deschambault</td>\n",
       "      <td>2021</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265000</td>\n",
       "      <td>309425</td>\n",
       "      <td>290848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12946</th>\n",
       "      <td>Beauport</td>\n",
       "      <td>2018</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195999</td>\n",
       "      <td>300867</td>\n",
       "      <td>268569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25750</th>\n",
       "      <td>St-Georges</td>\n",
       "      <td>2013</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185000</td>\n",
       "      <td>287807</td>\n",
       "      <td>256786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26449</th>\n",
       "      <td>Drummondville</td>\n",
       "      <td>2013</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>340000</td>\n",
       "      <td>325366</td>\n",
       "      <td>373725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42579</th>\n",
       "      <td>Fabreville</td>\n",
       "      <td>2021</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>400000</td>\n",
       "      <td>377655</td>\n",
       "      <td>405629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19042</th>\n",
       "      <td>Charlesbourg</td>\n",
       "      <td>2017</td>\n",
       "      <td>912.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>268000</td>\n",
       "      <td>300806</td>\n",
       "      <td>272265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>Blainville</td>\n",
       "      <td>2019</td>\n",
       "      <td>3867.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>349000</td>\n",
       "      <td>535300</td>\n",
       "      <td>385911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       location  year  living_area  3_bedrooms  2_bedrooms  \\\n",
       "47648                      Alma  2021       1800.0           0           0   \n",
       "28551              Boucherville  2013       1183.0           0           0   \n",
       "39252                     Lvis  2005       1352.0           1           0   \n",
       "34697                  Gatineau  2010       1300.0           0           0   \n",
       "32964                Neufchatel  2011        952.0           1           0   \n",
       "23878              Boucherville  2013       2900.0           1           0   \n",
       "37645  St-Augustin-De-Desmaures  2008       1568.0           0           0   \n",
       "34727                La Prairie  2010       1674.0           0           0   \n",
       "46894              Deschambault  2021       1261.0           0           1   \n",
       "36602                   Chambly  2009       1584.0           0           0   \n",
       "48255                   Mercier  2021       1645.0           1           0   \n",
       "20484                  Gatineau  2016       1800.0           1           0   \n",
       "27711                 Longueuil  2013        988.0           0           0   \n",
       "24961                Sherbrooke  2015        840.0           0           1   \n",
       "18442                   Chambly  2016        960.0           0           0   \n",
       "3375      Ste-Marthe-Sur-Le-Lac  2020        920.0           1           0   \n",
       "43345                   Mercier  2021       1645.0           1           0   \n",
       "45749                Fabreville  2021        960.0           1           0   \n",
       "44162                  Beauport  2020       1191.0           1           0   \n",
       "15814                Blainville  2017       1060.0           0           0   \n",
       "13946                  Gatineau  2018       1260.0           1           0   \n",
       "50850     St-Ferrol-les-Neiges  2021       1560.0           0           0   \n",
       "4465                    Mercier  2020       1080.0           1           0   \n",
       "57354              Deschambault  2021       1261.0           0           1   \n",
       "12946                  Beauport  2018        850.0           1           0   \n",
       "25750                St-Georges  2013       1120.0           1           0   \n",
       "26449             Drummondville  2013       2000.0           0           0   \n",
       "42579                Fabreville  2021        960.0           1           0   \n",
       "19042              Charlesbourg  2017        912.0           0           0   \n",
       "9912                 Blainville  2019       3867.0           1           0   \n",
       "\n",
       "       4_bedrooms  5_bedrooms  6_bedrooms  1_bedrooms  1_bathrooms  \\\n",
       "47648           0           1           0           0            0   \n",
       "28551           0           1           0           0            0   \n",
       "39252           0           0           0           0            1   \n",
       "34697           0           1           0           0            0   \n",
       "32964           0           0           0           0            1   \n",
       "23878           0           0           0           0            0   \n",
       "37645           1           0           0           0            1   \n",
       "34727           0           1           0           0            0   \n",
       "46894           0           0           0           0            1   \n",
       "36602           1           0           0           0            1   \n",
       "48255           0           0           0           0            1   \n",
       "20484           0           0           0           0            0   \n",
       "27711           1           0           0           0            1   \n",
       "24961           0           0           0           0            0   \n",
       "18442           1           0           0           0            0   \n",
       "3375            0           0           0           0            0   \n",
       "43345           0           0           0           0            1   \n",
       "45749           0           0           0           0            0   \n",
       "44162           0           0           0           0            1   \n",
       "15814           1           0           0           0            1   \n",
       "13946           0           0           0           0            1   \n",
       "50850           0           1           0           0            0   \n",
       "4465            0           0           0           0            1   \n",
       "57354           0           0           0           0            1   \n",
       "12946           0           0           0           0            1   \n",
       "25750           0           0           0           0            1   \n",
       "26449           1           0           0           0            0   \n",
       "42579           0           0           0           0            0   \n",
       "19042           1           0           0           0            0   \n",
       "9912            0           0           0           0            0   \n",
       "\n",
       "       3_bathrooms  2_bathrooms  4_bathrooms  real price  sk predicted price  \\\n",
       "47648            0            1            0      284000              437759   \n",
       "28551            0            1            0      295000              301592   \n",
       "39252            0            0            0      155000              189011   \n",
       "34697            0            1            0      266000              280009   \n",
       "32964            0            0            0      265000              242681   \n",
       "23878            1            0            0      695000              475647   \n",
       "37645            0            0            0      265000              231030   \n",
       "34727            0            1            0      330500              308621   \n",
       "46894            0            0            0      265000              309425   \n",
       "36602            0            0            0      312000              222140   \n",
       "48255            0            0            0      612000              410806   \n",
       "20484            1            0            0      380000              449032   \n",
       "27711            0            0            0      232999              244119   \n",
       "24961            0            1            0      197000              247299   \n",
       "18442            0            1            0      244999              290467   \n",
       "3375             0            1            0      335000              394140   \n",
       "43345            0            0            0      612000              410806   \n",
       "45749            0            1            0      400000              377655   \n",
       "44162            0            0            0      332500              348178   \n",
       "15814            0            0            0      251000              284461   \n",
       "13946            0            0            0      319000              338971   \n",
       "50850            0            1            0      610000              453588   \n",
       "4465             0            0            0      455000              361267   \n",
       "57354            0            0            0      265000              309425   \n",
       "12946            0            0            0      195999              300867   \n",
       "25750            0            0            0      185000              287807   \n",
       "26449            0            1            0      340000              325366   \n",
       "42579            0            1            0      400000              377655   \n",
       "19042            0            1            0      268000              300806   \n",
       "9912             0            1            0      349000              535300   \n",
       "\n",
       "       tf predicted price  \n",
       "47648              306945  \n",
       "28551              331303  \n",
       "39252              190407  \n",
       "34697              276676  \n",
       "32964              235525  \n",
       "23878              621489  \n",
       "37645              274712  \n",
       "34727              371913  \n",
       "46894              290848  \n",
       "36602              297002  \n",
       "48255              623542  \n",
       "20484              424414  \n",
       "27711              279035  \n",
       "24961              221265  \n",
       "18442              300676  \n",
       "3375               293957  \n",
       "43345              623542  \n",
       "45749              405629  \n",
       "44162              350134  \n",
       "15814              318907  \n",
       "13946              278257  \n",
       "50850              617469  \n",
       "4465               354415  \n",
       "57354              290848  \n",
       "12946              268569  \n",
       "25750              256786  \n",
       "26449              373725  \n",
       "42579              405629  \n",
       "19042              272265  \n",
       "9912               385911  "
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64dddcbcaec4bb6385c138499a04ba94b2e3f1c047b570a9b11b84db929d6a00"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
