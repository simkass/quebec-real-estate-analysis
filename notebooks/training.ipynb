{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_addons as tfa\n",
    "import visualkeras\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings: 94639\n"
     ]
    }
   ],
   "source": [
    "listings_df = pd.read_csv('../data/processed/processed-listings.csv').dropna()\n",
    "print('Number of listings: ' + str(len(listings_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Style</th>\n",
       "      <th>Living Area</th>\n",
       "      <th>Lot Dimensions</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Listing Date</th>\n",
       "      <th>Listing Year</th>\n",
       "      <th>Year of Construction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Storey</td>\n",
       "      <td>2 storey</td>\n",
       "      <td>1191</td>\n",
       "      <td>4076</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2004</td>\n",
       "      <td>16</td>\n",
       "      <td>Beauport</td>\n",
       "      <td>332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bungalow</td>\n",
       "      <td>Open area</td>\n",
       "      <td>1261</td>\n",
       "      <td>9500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>1957</td>\n",
       "      <td>64</td>\n",
       "      <td>Portneuf</td>\n",
       "      <td>265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1645</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>2006</td>\n",
       "      <td>15</td>\n",
       "      <td>Mercier-Hochelaga-Maisonneuve</td>\n",
       "      <td>612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semi-detached</td>\n",
       "      <td>2 storey</td>\n",
       "      <td>2400</td>\n",
       "      <td>4471</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>1989</td>\n",
       "      <td>32</td>\n",
       "      <td>Gatineau</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1800</td>\n",
       "      <td>16090</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>1990</td>\n",
       "      <td>31</td>\n",
       "      <td>Lac-Saint-Jean-Est</td>\n",
       "      <td>284000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subtype      Style  Living Area  Lot Dimensions  Bedrooms  Bathrooms  \\\n",
       "0       2 Storey   2 storey         1191            4076         3          1   \n",
       "1       Bungalow  Open area         1261            9500         2          1   \n",
       "2      Townhouse    Unknown         1645            1360         3          1   \n",
       "3  Semi-detached   2 storey         2400            4471         4          2   \n",
       "4       2 Storey    Unknown         1800           16090         5          2   \n",
       "\n",
       "   Levels Listing Date  Listing Year  Year of Construction  Age  \\\n",
       "0       2   2020-12-01          2020                  2004   16   \n",
       "1       1   2021-12-01          2021                  1957   64   \n",
       "2       3   2021-11-01          2021                  2006   15   \n",
       "3       2   2021-12-01          2021                  1989   32   \n",
       "4       2   2021-09-01          2021                  1990   31   \n",
       "\n",
       "                        Location   Price  \n",
       "0                       Beauport  332500  \n",
       "1                       Portneuf  265000  \n",
       "2  Mercier-Hochelaga-Maisonneuve  612000  \n",
       "3                       Gatineau  360000  \n",
       "4             Lac-Saint-Jean-Est  284000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing columnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols = []\n",
    "one_hot_cols = ['Subtype', 'Location']\n",
    "numerical_cols = ['Living Area', 'Lot Dimensions', 'Bedrooms', 'Bathrooms', 'Levels', 'Listing Year', 'Age']\n",
    "target_col = ['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Location</th>\n",
       "      <th>Living Area</th>\n",
       "      <th>Lot Dimensions</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Listing Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Beauport</td>\n",
       "      <td>1191</td>\n",
       "      <td>4076</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bungalow</td>\n",
       "      <td>Portneuf</td>\n",
       "      <td>1261</td>\n",
       "      <td>9500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>64</td>\n",
       "      <td>265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Townhouse</td>\n",
       "      <td>Mercier-Hochelaga-Maisonneuve</td>\n",
       "      <td>1645</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semi-detached</td>\n",
       "      <td>Gatineau</td>\n",
       "      <td>2400</td>\n",
       "      <td>4471</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>32</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 Storey</td>\n",
       "      <td>Lac-Saint-Jean-Est</td>\n",
       "      <td>1800</td>\n",
       "      <td>16090</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>31</td>\n",
       "      <td>284000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subtype                       Location  Living Area  Lot Dimensions  \\\n",
       "0       2 Storey                       Beauport         1191            4076   \n",
       "1       Bungalow                       Portneuf         1261            9500   \n",
       "2      Townhouse  Mercier-Hochelaga-Maisonneuve         1645            1360   \n",
       "3  Semi-detached                       Gatineau         2400            4471   \n",
       "4       2 Storey             Lac-Saint-Jean-Est         1800           16090   \n",
       "\n",
       "   Bedrooms  Bathrooms  Levels  Listing Year  Age   Price  \n",
       "0         3          1       2          2020   16  332500  \n",
       "1         2          1       1          2021   64  265000  \n",
       "2         3          1       3          2021   15  612000  \n",
       "3         4          2       2          2021   32  360000  \n",
       "4         5          2       2          2021   31  284000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df = listings_df[ordinal_cols + one_hot_cols + numerical_cols + target_col]\n",
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:06<00:00,  1.32it/s]\n",
      "100%|██████████| 111/111 [01:34<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def oh_encode(df_line, col, new_col, val):\n",
    "    if df_line[col] == val:\n",
    "        return df_line[new_col] + 1\n",
    "    else:\n",
    "        return df_line[new_col]\n",
    "\n",
    "for col in one_hot_cols:\n",
    "    for val in tqdm(listings_df[col].unique()):   \n",
    "        new_col = str(val) + '_' + col\n",
    "        listings_df[new_col] = 0\n",
    "        listings_df[new_col] = listings_df.apply(oh_encode, args=(col, new_col, val), axis=1)\n",
    "\n",
    "    listings_df = listings_df.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Living Area</th>\n",
       "      <th>Lot Dimensions</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Listing Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Price</th>\n",
       "      <th>2 Storey_Subtype</th>\n",
       "      <th>Bungalow_Subtype</th>\n",
       "      <th>...</th>\n",
       "      <th>Kirkland_Location</th>\n",
       "      <th>Senneville, Baie-D'Urfé &amp; Saint-Anne-de-Bellevue_Location</th>\n",
       "      <th>Le Sud-Ouest_Location</th>\n",
       "      <th>Verdun_Location</th>\n",
       "      <th>Beaconsfield_Location</th>\n",
       "      <th>Saint-Léonard_Location</th>\n",
       "      <th>Ville de Mont-Royal_Location</th>\n",
       "      <th>Outremont_Location</th>\n",
       "      <th>Westmount_Location</th>\n",
       "      <th>Ville-Marie_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191</td>\n",
       "      <td>4076</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>332500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1261</td>\n",
       "      <td>9500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>64</td>\n",
       "      <td>265000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1645</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>612000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2400</td>\n",
       "      <td>4471</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>32</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1800</td>\n",
       "      <td>16090</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>31</td>\n",
       "      <td>284000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Living Area  Lot Dimensions  Bedrooms  Bathrooms  Levels  Listing Year  \\\n",
       "0         1191            4076         3          1       2          2020   \n",
       "1         1261            9500         2          1       1          2021   \n",
       "2         1645            1360         3          1       3          2021   \n",
       "3         2400            4471         4          2       2          2021   \n",
       "4         1800           16090         5          2       2          2021   \n",
       "\n",
       "   Age   Price  2 Storey_Subtype  Bungalow_Subtype  ...  Kirkland_Location  \\\n",
       "0   16  332500                 1                 0  ...                  0   \n",
       "1   64  265000                 0                 1  ...                  0   \n",
       "2   15  612000                 0                 0  ...                  0   \n",
       "3   32  360000                 0                 0  ...                  0   \n",
       "4   31  284000                 1                 0  ...                  0   \n",
       "\n",
       "   Senneville, Baie-D'Urfé & Saint-Anne-de-Bellevue_Location  \\\n",
       "0                                                  0           \n",
       "1                                                  0           \n",
       "2                                                  0           \n",
       "3                                                  0           \n",
       "4                                                  0           \n",
       "\n",
       "   Le Sud-Ouest_Location  Verdun_Location  Beaconsfield_Location  \\\n",
       "0                      0                0                      0   \n",
       "1                      0                0                      0   \n",
       "2                      0                0                      0   \n",
       "3                      0                0                      0   \n",
       "4                      0                0                      0   \n",
       "\n",
       "   Saint-Léonard_Location  Ville de Mont-Royal_Location  Outremont_Location  \\\n",
       "0                       0                             0                   0   \n",
       "1                       0                             0                   0   \n",
       "2                       0                             0                   0   \n",
       "3                       0                             0                   0   \n",
       "4                       0                             0                   0   \n",
       "\n",
       "   Westmount_Location  Ville-Marie_Location  \n",
       "0                   0                     0  \n",
       "1                   0                     0  \n",
       "2                   0                     0  \n",
       "3                   0                     0  \n",
       "4                   0                     0  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Living Area</th>\n",
       "      <th>Lot Dimensions</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Listing Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Price</th>\n",
       "      <th>2 Storey_Subtype</th>\n",
       "      <th>Bungalow_Subtype</th>\n",
       "      <th>...</th>\n",
       "      <th>Kirkland_Location</th>\n",
       "      <th>Senneville, Baie-D'Urfé &amp; Saint-Anne-de-Bellevue_Location</th>\n",
       "      <th>Le Sud-Ouest_Location</th>\n",
       "      <th>Verdun_Location</th>\n",
       "      <th>Beaconsfield_Location</th>\n",
       "      <th>Saint-Léonard_Location</th>\n",
       "      <th>Ville de Mont-Royal_Location</th>\n",
       "      <th>Outremont_Location</th>\n",
       "      <th>Westmount_Location</th>\n",
       "      <th>Ville-Marie_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191</td>\n",
       "      <td>4076</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>332500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1261</td>\n",
       "      <td>9500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>64</td>\n",
       "      <td>265000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1645</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>612000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2400</td>\n",
       "      <td>4471</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>32</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1800</td>\n",
       "      <td>16090</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>31</td>\n",
       "      <td>284000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Living Area  Lot Dimensions  Bedrooms  Bathrooms  Levels  Listing Year  \\\n",
       "0         1191            4076         3          1       2          2020   \n",
       "1         1261            9500         2          1       1          2021   \n",
       "2         1645            1360         3          1       3          2021   \n",
       "3         2400            4471         4          2       2          2021   \n",
       "4         1800           16090         5          2       2          2021   \n",
       "\n",
       "   Age   Price  2 Storey_Subtype  Bungalow_Subtype  ...  Kirkland_Location  \\\n",
       "0   16  332500                 1                 0  ...                  0   \n",
       "1   64  265000                 0                 1  ...                  0   \n",
       "2   15  612000                 0                 0  ...                  0   \n",
       "3   32  360000                 0                 0  ...                  0   \n",
       "4   31  284000                 1                 0  ...                  0   \n",
       "\n",
       "   Senneville, Baie-D'Urfé & Saint-Anne-de-Bellevue_Location  \\\n",
       "0                                                  0           \n",
       "1                                                  0           \n",
       "2                                                  0           \n",
       "3                                                  0           \n",
       "4                                                  0           \n",
       "\n",
       "   Le Sud-Ouest_Location  Verdun_Location  Beaconsfield_Location  \\\n",
       "0                      0                0                      0   \n",
       "1                      0                0                      0   \n",
       "2                      0                0                      0   \n",
       "3                      0                0                      0   \n",
       "4                      0                0                      0   \n",
       "\n",
       "   Saint-Léonard_Location  Ville de Mont-Royal_Location  Outremont_Location  \\\n",
       "0                       0                             0                   0   \n",
       "1                       0                             0                   0   \n",
       "2                       0                             0                   0   \n",
       "3                       0                             0                   0   \n",
       "4                       0                             0                   0   \n",
       "\n",
       "   Westmount_Location  Ville-Marie_Location  \n",
       "0                   0                     0  \n",
       "1                   0                     0  \n",
       "2                   0                     0  \n",
       "3                   0                     0  \n",
       "4                   0                     0  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoders = {}\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    ordinal_encoders[col] = OrdinalEncoder()\n",
    "    ordinal_encoders[col].fit(listings_df[[col]])\n",
    "    listings_df[col] = ordinal_encoders[col].transform(listings_df[[col]])\n",
    "\n",
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data (Test/Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = listings_df[target_col]\n",
    "X = listings_df.drop(columns=target_col)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data\n",
    "Using Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cols = numerical_cols + ordinal_cols\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "for col in scaled_cols:\n",
    "    scalers[col] = MinMaxScaler()\n",
    "    X_train[col] = scalers[col].fit_transform(X_train[[col]])\n",
    "    X_test[col] = scalers[col].transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Living Area</th>\n",
       "      <th>Lot Dimensions</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Listing Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>2 Storey_Subtype</th>\n",
       "      <th>Bungalow_Subtype</th>\n",
       "      <th>Townhouse_Subtype</th>\n",
       "      <th>...</th>\n",
       "      <th>Kirkland_Location</th>\n",
       "      <th>Senneville, Baie-D'Urfé &amp; Saint-Anne-de-Bellevue_Location</th>\n",
       "      <th>Le Sud-Ouest_Location</th>\n",
       "      <th>Verdun_Location</th>\n",
       "      <th>Beaconsfield_Location</th>\n",
       "      <th>Saint-Léonard_Location</th>\n",
       "      <th>Ville de Mont-Royal_Location</th>\n",
       "      <th>Outremont_Location</th>\n",
       "      <th>Westmount_Location</th>\n",
       "      <th>Ville-Marie_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31038</th>\n",
       "      <td>0.116444</td>\n",
       "      <td>0.029899</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.130178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46861</th>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.177596</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.213018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33840</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.245919</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.147929</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60778</th>\n",
       "      <td>0.137333</td>\n",
       "      <td>0.163232</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.130178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56747</th>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Living Area  Lot Dimensions  Bedrooms  Bathrooms  Levels  Listing Year  \\\n",
       "31038     0.116444        0.029899      0.50   0.333333     0.5          0.80   \n",
       "46861     0.355556        0.177596      0.75   0.333333     0.5          0.65   \n",
       "33840     0.400000        0.245919      1.00   0.666667     0.5          0.70   \n",
       "60778     0.137333        0.163232      0.75   0.333333     0.5          0.50   \n",
       "56747     0.308000        0.121212      1.00   0.666667     0.5          0.55   \n",
       "\n",
       "            Age  2 Storey_Subtype  Bungalow_Subtype  Townhouse_Subtype  ...  \\\n",
       "31038  0.130178                 0                 0                  1  ...   \n",
       "46861  0.213018                 0                 0                  0  ...   \n",
       "33840  0.147929                 1                 0                  0  ...   \n",
       "60778  0.130178                 0                 0                  0  ...   \n",
       "56747  0.029586                 1                 0                  0  ...   \n",
       "\n",
       "       Kirkland_Location  \\\n",
       "31038                  0   \n",
       "46861                  0   \n",
       "33840                  0   \n",
       "60778                  0   \n",
       "56747                  0   \n",
       "\n",
       "       Senneville, Baie-D'Urfé & Saint-Anne-de-Bellevue_Location  \\\n",
       "31038                                                  0           \n",
       "46861                                                  0           \n",
       "33840                                                  0           \n",
       "60778                                                  0           \n",
       "56747                                                  0           \n",
       "\n",
       "       Le Sud-Ouest_Location  Verdun_Location  Beaconsfield_Location  \\\n",
       "31038                      0                0                      0   \n",
       "46861                      0                0                      0   \n",
       "33840                      0                0                      0   \n",
       "60778                      0                0                      0   \n",
       "56747                      0                0                      0   \n",
       "\n",
       "       Saint-Léonard_Location  Ville de Mont-Royal_Location  \\\n",
       "31038                       0                             0   \n",
       "46861                       0                             0   \n",
       "33840                       0                             0   \n",
       "60778                       0                             0   \n",
       "56747                       0                             0   \n",
       "\n",
       "       Outremont_Location  Westmount_Location  Ville-Marie_Location  \n",
       "31038                   0                   0                     0  \n",
       "46861                   0                   0                     0  \n",
       "33840                   0                   0                     0  \n",
       "60778                   0                   0                     0  \n",
       "56747                   0                   0                     0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_target = True\n",
    "\n",
    "if scale_target:\n",
    "    target_scaler = MinMaxScaler()\n",
    "\n",
    "    y_train = target_scaler.fit_transform(y_train)\n",
    "    y_test = target_scaler.fit_transform(y_test)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 500)               64000     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,201\n",
      "Trainable params: 119,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=500 input_dim=X_train.shape[-1], activation= \"relu\"))\n",
    "model.add(Dense(100, activation= \"relu\"))\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.0639 - val_loss: 0.0163\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0168 - val_loss: 0.0193\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0185 - val_loss: 0.0277\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0265 - val_loss: 0.0228\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0218 - val_loss: 0.0152\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0026 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(), loss=\"mean_squared_error\")\n",
    "history = model.fit(X_train, y_train, batch_size=80000, epochs=500, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.figure(figsize=(14, 8))\n",
    "  plt.rcParams.update({'font.size': 22})\n",
    "  plt.plot(history.history['loss'], 'dodgerblue', label='training loss')\n",
    "  plt.plot(history.history['val_loss'], 'orangered', label='validation loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MSE]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.savefig('./figures/training/training.png', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = target_scaler.inverse_transform(model.predict(X_test))\n",
    "real_prices = target_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = X_test.copy()\n",
    "\n",
    "for col in scaled_cols:\n",
    "    test_df[col] = scalers[col].inverse_transform(test_df[[col]])\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    test_df[col] = ordinal_encoders[col].inverse_transform(test_df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['real price'] = list(real_prices)\n",
    "d['predicted price'] = list(predicted_prices)\n",
    "\n",
    "test_df['real price'] = d['real price']\n",
    "test_df['predicted price'] = d['predicted price']\n",
    "\n",
    "test_df['real price'] = test_df['real price'].astype(int)\n",
    "test_df['predicted price'] = test_df['predicted price'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Living Area</th>\n",
       "      <th>Lot Dimensions</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Levels</th>\n",
       "      <th>Listing Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>2 Storey_Subtype</th>\n",
       "      <th>Bungalow_Subtype</th>\n",
       "      <th>Townhouse_Subtype</th>\n",
       "      <th>...</th>\n",
       "      <th>Le Sud-Ouest_Location</th>\n",
       "      <th>Verdun_Location</th>\n",
       "      <th>Beaconsfield_Location</th>\n",
       "      <th>Saint-Léonard_Location</th>\n",
       "      <th>Ville de Mont-Royal_Location</th>\n",
       "      <th>Outremont_Location</th>\n",
       "      <th>Westmount_Location</th>\n",
       "      <th>Ville-Marie_Location</th>\n",
       "      <th>real price</th>\n",
       "      <th>predicted price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72597</th>\n",
       "      <td>1018.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190000</td>\n",
       "      <td>182475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47050</th>\n",
       "      <td>1119.0</td>\n",
       "      <td>6649.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305000</td>\n",
       "      <td>290251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>760.0</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250000</td>\n",
       "      <td>224970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20111</th>\n",
       "      <td>738.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225000</td>\n",
       "      <td>200427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80641</th>\n",
       "      <td>1135.0</td>\n",
       "      <td>9291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265000</td>\n",
       "      <td>309519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60626</th>\n",
       "      <td>864.0</td>\n",
       "      <td>5261.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195000</td>\n",
       "      <td>195480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28966</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>11136.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359000</td>\n",
       "      <td>300177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63544</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>13570.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>425000</td>\n",
       "      <td>438934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>2432.0</td>\n",
       "      <td>9291.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>610000</td>\n",
       "      <td>463487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20327</th>\n",
       "      <td>1127.0</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252999</td>\n",
       "      <td>344943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48443</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>254900</td>\n",
       "      <td>250562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81465</th>\n",
       "      <td>850.0</td>\n",
       "      <td>9291.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152000</td>\n",
       "      <td>142377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Living Area  Lot Dimensions  Bedrooms  Bathrooms  Levels  Listing Year  \\\n",
       "72597       1018.0          4400.0       3.0        2.0     1.0        2005.0   \n",
       "47050       1119.0          6649.0       3.0        2.0     1.0        2015.0   \n",
       "5832         760.0          3240.0       3.0        1.0     2.0        2021.0   \n",
       "20111        738.0          5400.0       2.0        1.0     1.0        2019.0   \n",
       "80641       1135.0          9291.0       2.0        1.0     1.0        2019.0   \n",
       "60626        864.0          5261.0       3.0        1.0     1.0        2011.0   \n",
       "28966       1980.0         11136.0       4.0        2.0     1.0        2017.0   \n",
       "63544       2800.0         13570.0       5.0        2.0     1.0        2010.0   \n",
       "4014        2432.0          9291.0       5.0        2.0     2.0        2021.0   \n",
       "20327       1127.0          6380.0       4.0        2.0     1.0        2019.0   \n",
       "48443       1200.0          3059.0       3.0        2.0     2.0        2014.0   \n",
       "81465        850.0          9291.0       1.0        1.0     1.0        2018.0   \n",
       "\n",
       "        Age  2 Storey_Subtype  Bungalow_Subtype  Townhouse_Subtype  ...  \\\n",
       "72597  78.0                 0                 1                  0  ...   \n",
       "47050  52.0                 0                 1                  0  ...   \n",
       "5832   36.0                 0                 0                  0  ...   \n",
       "20111  50.0                 0                 1                  0  ...   \n",
       "80641   4.0                 0                 0                  0  ...   \n",
       "60626  21.0                 0                 1                  0  ...   \n",
       "28966  34.0                 0                 0                  0  ...   \n",
       "63544  50.0                 0                 1                  0  ...   \n",
       "4014    2.0                 1                 0                  0  ...   \n",
       "20327  27.0                 0                 0                  0  ...   \n",
       "48443  12.0                 0                 0                  0  ...   \n",
       "81465  26.0                 0                 0                  0  ...   \n",
       "\n",
       "       Le Sud-Ouest_Location  Verdun_Location  Beaconsfield_Location  \\\n",
       "72597                      0                0                      0   \n",
       "47050                      0                0                      0   \n",
       "5832                       0                0                      0   \n",
       "20111                      0                0                      0   \n",
       "80641                      0                0                      0   \n",
       "60626                      0                0                      0   \n",
       "28966                      0                0                      0   \n",
       "63544                      0                0                      0   \n",
       "4014                       0                0                      0   \n",
       "20327                      0                0                      0   \n",
       "48443                      0                0                      0   \n",
       "81465                      0                0                      0   \n",
       "\n",
       "       Saint-Léonard_Location  Ville de Mont-Royal_Location  \\\n",
       "72597                       0                             0   \n",
       "47050                       0                             0   \n",
       "5832                        0                             0   \n",
       "20111                       0                             0   \n",
       "80641                       0                             0   \n",
       "60626                       0                             0   \n",
       "28966                       0                             0   \n",
       "63544                       0                             0   \n",
       "4014                        0                             0   \n",
       "20327                       0                             0   \n",
       "48443                       0                             0   \n",
       "81465                       0                             0   \n",
       "\n",
       "       Outremont_Location  Westmount_Location  Ville-Marie_Location  \\\n",
       "72597                   0                   0                     0   \n",
       "47050                   0                   0                     0   \n",
       "5832                    0                   0                     0   \n",
       "20111                   0                   0                     0   \n",
       "80641                   0                   0                     0   \n",
       "60626                   0                   0                     0   \n",
       "28966                   0                   0                     0   \n",
       "63544                   0                   0                     0   \n",
       "4014                    0                   0                     0   \n",
       "20327                   0                   0                     0   \n",
       "48443                   0                   0                     0   \n",
       "81465                   0                   0                     0   \n",
       "\n",
       "       real price  predicted price  \n",
       "72597      190000           182475  \n",
       "47050      305000           290251  \n",
       "5832       250000           224970  \n",
       "20111      225000           200427  \n",
       "80641      265000           309519  \n",
       "60626      195000           195480  \n",
       "28966      359000           300177  \n",
       "63544      425000           438934  \n",
       "4014       610000           463487  \n",
       "20327      252999           344943  \n",
       "48443      254900           250562  \n",
       "81465      152000           142377  \n",
       "\n",
       "[12 rows x 129 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = abs(predicted_prices - real_prices)\n",
    "errors_small = list(filter(lambda x: x < 100000, errors))\n",
    "errors_pct = 100 * (abs(predicted_prices - real_prices) / real_prices)\n",
    "errors_pct_small = list(filter(lambda x: x < 100, errors_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Mean ($): 38913$\n",
      "Error std ($): 42502$\n",
      "Error Mean (%): 14.87%\n",
      "Error std (%): 18.46%\n"
     ]
    }
   ],
   "source": [
    "e_avg = int(np.mean(errors))\n",
    "e_std = int(np.std(errors))\n",
    "epct_avg = round(np.mean(errors_pct), 2)\n",
    "epct_std = round(np.std(errors_pct), 2)\n",
    "\n",
    "print('Error Mean ($): ' + str(e_avg) + '$')\n",
    "print('Error std ($): ' + str(e_std) + '$')\n",
    "print('Error Mean (%): ' + str(epct_avg) + '%')\n",
    "print('Error std (%): ' + str(epct_std) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model\\assets\n"
     ]
    }
   ],
   "source": [
    "filepath = '../model'\n",
    "\n",
    "save_model = False\n",
    "if save_model:\n",
    "    model.save(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in scalers.keys():\n",
    "    joblib.dump(scalers[key], './scalers/' + key + '_scaler.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scalers/Price_scaler.pkl']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(target_scaler, './scalers/Price_scaler.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unencode test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unencode_column(df: pd.DataFrame, column: str):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unencode(df):\n",
    "    for column in one_hot_cols:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35baa29fccf03004b73c6d7efa1229fc55fcd4d7e436d14040fdb80c99cecdea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
